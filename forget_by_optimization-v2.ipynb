{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T01:19:19.688327Z",
     "start_time": "2024-05-16T01:19:19.375159Z"
    }
   },
   "source": [
    "# libraries\n",
    "import torch\n",
    "from model import get_core_model_params, get_trained_linear, freeze\n",
    "from dataset import split_user_train_dataset_to_remaining_forget, get_remaining_forget_loader\n",
    "from utils import params_to_device\n",
    "from loss import MSELossDiv2\n",
    "import os\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "\n",
    "device = 'cpu:0' if torch.cuda.is_available() else 'cpu'"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T00:30:42.167939Z",
     "start_time": "2024-05-16T00:30:41.761093Z"
    }
   },
   "source": [
    "# load pretrained model\n",
    "exp_path = 'checkpoint/05152024-011132-train-user-data-resnet18-cifar10-last1/'\n",
    "core_model_state_dict = get_core_model_params(os.path.join(exp_path, '05152024_011132_train_user_data_resnet18_cifar10_last1_core_model.pth'), 'cpu')\n",
    "_, mixed_linear = get_trained_linear(os.path.join(exp_path, '05152024_011132_train_user_data_resnet18_cifar10_last1.pth'), 'resnet18', 'cifar10', 1, activation_variant=True)\n",
    "del _\n",
    "exp_path = './checkpoint/tmp/'\n",
    "\n",
    "mixed_linear = mixed_linear.to(device)\n",
    "freeze(mixed_linear)\n",
    "\n",
    "core_model_state_dict = params_to_device(core_model_state_dict, device)\n",
    "\n",
    "## split dataset into remaning and forget\n",
    "remaining_dataset, forget_dataset = split_user_train_dataset_to_remaining_forget('cifar10-act', 'resnet18', 0.1, number_of_linearized_components=1)\n",
    "remain_loader, forget_loader = get_remaining_forget_loader(remaining_dataset, forget_dataset, 256)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T00:31:13.260522Z",
     "start_time": "2024-05-16T00:31:01.634841Z"
    }
   },
   "source": [
    "# calculate the hessian on the last linear layer for both remaning and forget\n",
    "def calculate_hessian(loader, exp_path, mode='forget'):\n",
    "    print('{} hessian'.format(mode))\n",
    "    hessian = None\n",
    "    sample_count = 0\n",
    "    with torch.no_grad():\n",
    "        for iter, (data, _) in enumerate(loader):\n",
    "            data = data.to(device)\n",
    "            act = data.unsqueeze(-1)\n",
    "            batched_hessian = act @ act.permute(0, 2, 1)\n",
    "            if hessian is None:\n",
    "                hessian = torch.sum(batched_hessian, dim=0).clone().detach().to('cpu')\n",
    "            else:\n",
    "                hessian += torch.sum(batched_hessian, dim=0).clone().detach().to('cpu')\n",
    "            sample_count += data.shape[0]\n",
    "            if (iter + 1) % 50 == 0 or (iter + 1) == len(loader):\n",
    "                print('iter: {}/{}'.format(iter + 1, len(loader))) \n",
    "    hessian = hessian / sample_count\n",
    "    torch.save({'hessian': hessian}, os.path.join(exp_path, '05152024_011132_train_user_data_resnet18_cifar10_last1_{}_hessian.pth'.format(mode)))\n",
    "    return hessian\n",
    "\n",
    "forget_hessian = calculate_hessian(forget_loader, exp_path, mode='forget')\n",
    "remain_hessian = calculate_hessian(remain_loader, exp_path, mode='remain')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T00:35:15.397474Z",
     "start_time": "2024-05-16T00:35:15.272712Z"
    }
   },
   "source": [
    "# sample perturbed parameters\n",
    "## perturb from gradient direction\n",
    "## NOTE: we can analyze the effects of sampling different perturbations and its importance\n",
    "\n",
    "trained_mixed_linear_weights = [key.clone().detach().to('cpu') for key in mixed_linear.tangents.values()]\n",
    "num_of_perturbations = 50\n",
    "scale_random = 0.01\n",
    "\n",
    "# using default random perturbation\n",
    "perturbations = []\n",
    "perturbed_weights = []\n",
    "for _ in range(num_of_perturbations):\n",
    "    curr_perturb = [torch.randn(*weight.shape) * scale_random for weight in trained_mixed_linear_weights]\n",
    "    curr_perturbed_weight = [weight + perturb for weight, perturb in zip(trained_mixed_linear_weights, curr_perturb)]\n",
    "    perturbations.append(curr_perturb)\n",
    "    perturbed_weights.append(curr_perturbed_weight)\n",
    "torch.save({'perturbations': perturbations}, os.path.join(exp_path, '05152024_011132_train_user_data_resnet18_cifar10_last1_perturbations.pth'))\n",
    "torch.save({'perturbed_weights': perturbed_weights}, os.path.join(exp_path, '05152024_011132_train_user_data_resnet18_cifar10_last1_perturbed_weights.pth'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T00:35:36.159270Z",
     "start_time": "2024-05-16T00:35:30.635560Z"
    }
   },
   "source": [
    "# find out loss differences (L_forget)\n",
    "criterion = MSELossDiv2()\n",
    "forget_loss_differences = torch.zeros(num_of_perturbations).to(device)\n",
    "sample_count = 0\n",
    "mixed_linear.eval()\n",
    "with torch.no_grad():\n",
    "    for iter, (data, label) in enumerate(forget_loader):\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        label = label * 5\n",
    "        preds = mixed_linear(core_model_state_dict, data)\n",
    "        actual_loss = criterion(preds, label)\n",
    "        sample_count += data.shape[0]\n",
    "        for perturb_idx, perturbed_weight in enumerate(perturbed_weights):\n",
    "            mixed_linear.to('cpu')\n",
    "            state_dict = mixed_linear.state_dict()\n",
    "            for key, perturbed in zip(state_dict.keys(), perturbed_weight):\n",
    "                state_dict[key] = perturbed\n",
    "            mixed_linear.load_state_dict(state_dict)\n",
    "            mixed_linear.to(device)\n",
    "            perturbed_preds = mixed_linear(core_model_state_dict, data)\n",
    "            perturbed_loss = criterion(perturbed_preds, label)\n",
    "            forget_loss_differences[perturb_idx] += (perturbed_loss - actual_loss) * 2 * data.shape[0]\n",
    "            if (perturb_idx + 1) % 10 == 0 or (perturb_idx + 1) == len(forget_loader):\n",
    "                print('iter: {}/{} perturb: {}/{}'.format(iter + 1, len(forget_loader), perturb_idx + 1, len(perturbed_weights)))\n",
    "    forget_loss_differences = forget_loss_differences / sample_count\n",
    "    forget_loss_differences = forget_loss_differences.to('cpu')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T01:18:54.598888Z",
     "start_time": "2024-05-16T01:18:54.594661Z"
    },
    "collapsed": false
   },
   "source": [
    "exact_hessian = (forget_hessian * len(forget_dataset) + remain_hessian * len(remaining_dataset)) / (len(remaining_dataset) + len(forget_dataset))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-16T01:34:43.694859Z"
    },
    "is_executing": true
   },
   "source": [
    "# set optimization problem\n",
    "H = cp.Variable(exact_hessian.shape)\n",
    "# exact_H = cp.kron(H, np.eye(perturbations[0][0].shape[0]))\n",
    "# losses = cp.matmul(stacked_linearized_perturbations.T, cp.matmul(exact_H, stacked_linearized_perturbations))\n",
    "loss = None\n",
    "for perturbation in perturbations:\n",
    "    perturbation = perturbation[0].numpy()\n",
    "    if loss is None:\n",
    "        loss = cp.trace(cp.matmul(perturbation, cp.matmul(H, perturbation.T)))\n",
    "    else:\n",
    "        loss = loss + cp.trace(cp.matmul(perturbation, cp.matmul(H, perturbation.T)))\n",
    "loss = (loss / (2 * len(perturbations))) - np.mean(forget_loss_differences.numpy())\n",
    "# loss = (cp.trace(losses) / (2 * losses.shape[0])) - np.mean(forget_loss_differences.numpy())\n",
    "objective = cp.Minimize(loss)\n",
    "constraints = [H >> 0, cp.trace(H) >= 0, H >> forget_hessian.numpy()]\n",
    "problem = cp.Problem(objective, constraints)\n",
    "problem.solve(verbose=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "exact_hessian"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "source": [
    "H = torch.tensor(H.value)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "torch.save({\n",
    "    'predicted_hessian': H  \n",
    "}, os.path.join(exp_path, '05152024_011132_train_user_data_resnet18_cifar10_last1_predicted_hessian.pth'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "source": [
    "torch.load(os.path.join(exp_path, '05152024_011132_train_user_data_resnet18_cifar10_last1_predicted_hessian.pth'))"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-stable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
