{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T01:19:19.688327Z",
     "start_time": "2024-05-16T01:19:19.375159Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/umityigitbsrn/miniconda3/envs/pytorch-stable/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "import torch\n",
    "from model import get_core_model_params, get_trained_linear, freeze\n",
    "from dataset import split_user_train_dataset_to_remaining_forget, get_remaining_forget_loader\n",
    "from utils import params_to_device\n",
    "from loss import MSELossDiv2\n",
    "import os\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "\n",
    "device = 'cpu:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T00:30:42.167939Z",
     "start_time": "2024-05-16T00:30:41.761093Z"
    }
   },
   "outputs": [],
   "source": [
    "# load pretrained model\n",
    "exp_path = 'checkpoint/05152024-011132-train-user-data-resnet18-cifar10-last1/'\n",
    "core_model_state_dict = get_core_model_params(os.path.join(exp_path, '05152024_011132_train_user_data_resnet18_cifar10_last1_core_model.pth'), 'cpu')\n",
    "_, mixed_linear = get_trained_linear(os.path.join(exp_path, '05152024_011132_train_user_data_resnet18_cifar10_last1.pth'), 'resnet18', 'cifar10', 1, activation_variant=True)\n",
    "del _\n",
    "exp_path = './checkpoint/tmp/'\n",
    "\n",
    "mixed_linear = mixed_linear.to(device)\n",
    "freeze(mixed_linear)\n",
    "\n",
    "core_model_state_dict = params_to_device(core_model_state_dict, device)\n",
    "\n",
    "## split dataset into remaning and forget\n",
    "remaining_dataset, forget_dataset = split_user_train_dataset_to_remaining_forget('cifar10-act', 'resnet18', 0.1, number_of_linearized_components=1)\n",
    "remain_loader, forget_loader = get_remaining_forget_loader(remaining_dataset, forget_dataset, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T00:31:13.260522Z",
     "start_time": "2024-05-16T00:31:01.634841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forget hessian\n",
      "iter: 20/20\n",
      "remain hessian\n",
      "iter: 50/176\n",
      "iter: 100/176\n",
      "iter: 150/176\n",
      "iter: 176/176\n"
     ]
    }
   ],
   "source": [
    "# calculate the hessian on the last linear layer for both remaning and forget\n",
    "def calculate_hessian(loader, exp_path, mode='forget'):\n",
    "    print('{} hessian'.format(mode))\n",
    "    hessian = None\n",
    "    sample_count = 0\n",
    "    with torch.no_grad():\n",
    "        for iter, (data, _) in enumerate(loader):\n",
    "            data = data.to(device)\n",
    "            act = data.unsqueeze(-1)\n",
    "            batched_hessian = act @ act.permute(0, 2, 1)\n",
    "            if hessian is None:\n",
    "                hessian = torch.sum(batched_hessian, dim=0).clone().detach().to('cpu')\n",
    "            else:\n",
    "                hessian += torch.sum(batched_hessian, dim=0).clone().detach().to('cpu')\n",
    "            sample_count += data.shape[0]\n",
    "            if (iter + 1) % 50 == 0 or (iter + 1) == len(loader):\n",
    "                print('iter: {}/{}'.format(iter + 1, len(loader))) \n",
    "    hessian = hessian / sample_count\n",
    "    torch.save({'hessian': hessian}, os.path.join(exp_path, '05152024_011132_train_user_data_resnet18_cifar10_last1_{}_hessian.pth'.format(mode)))\n",
    "    return hessian\n",
    "\n",
    "forget_hessian = calculate_hessian(forget_loader, exp_path, mode='forget')\n",
    "remain_hessian = calculate_hessian(remain_loader, exp_path, mode='remain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T00:35:15.397474Z",
     "start_time": "2024-05-16T00:35:15.272712Z"
    }
   },
   "outputs": [],
   "source": [
    "# sample perturbed parameters\n",
    "## perturb from gradient direction\n",
    "## NOTE: we can analyze the effects of sampling different perturbations and its importance\n",
    "\n",
    "trained_mixed_linear_weights = [key.clone().detach().to('cpu') for key in mixed_linear.tangents.values()]\n",
    "num_of_perturbations = 50\n",
    "scale_random = 0.01\n",
    "\n",
    "# using default random perturbation\n",
    "perturbations = []\n",
    "perturbed_weights = []\n",
    "for _ in range(num_of_perturbations):\n",
    "    curr_perturb = [torch.randn(*weight.shape) * scale_random for weight in trained_mixed_linear_weights]\n",
    "    curr_perturbed_weight = [weight + perturb for weight, perturb in zip(trained_mixed_linear_weights, curr_perturb)]\n",
    "    perturbations.append(curr_perturb)\n",
    "    perturbed_weights.append(curr_perturbed_weight)\n",
    "torch.save({'perturbations': perturbations}, os.path.join(exp_path, '05152024_011132_train_user_data_resnet18_cifar10_last1_perturbations.pth'))\n",
    "torch.save({'perturbed_weights': perturbed_weights}, os.path.join(exp_path, '05152024_011132_train_user_data_resnet18_cifar10_last1_perturbed_weights.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T00:35:36.159270Z",
     "start_time": "2024-05-16T00:35:30.635560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1/20 perturb: 10/50\n",
      "iter: 1/20 perturb: 20/50\n",
      "iter: 1/20 perturb: 30/50\n",
      "iter: 1/20 perturb: 40/50\n",
      "iter: 1/20 perturb: 50/50\n",
      "iter: 2/20 perturb: 10/50\n",
      "iter: 2/20 perturb: 20/50\n",
      "iter: 2/20 perturb: 30/50\n",
      "iter: 2/20 perturb: 40/50\n",
      "iter: 2/20 perturb: 50/50\n",
      "iter: 3/20 perturb: 10/50\n",
      "iter: 3/20 perturb: 20/50\n",
      "iter: 3/20 perturb: 30/50\n",
      "iter: 3/20 perturb: 40/50\n",
      "iter: 3/20 perturb: 50/50\n",
      "iter: 4/20 perturb: 10/50\n",
      "iter: 4/20 perturb: 20/50\n",
      "iter: 4/20 perturb: 30/50\n",
      "iter: 4/20 perturb: 40/50\n",
      "iter: 4/20 perturb: 50/50\n",
      "iter: 5/20 perturb: 10/50\n",
      "iter: 5/20 perturb: 20/50\n",
      "iter: 5/20 perturb: 30/50\n",
      "iter: 5/20 perturb: 40/50\n",
      "iter: 5/20 perturb: 50/50\n",
      "iter: 6/20 perturb: 10/50\n",
      "iter: 6/20 perturb: 20/50\n",
      "iter: 6/20 perturb: 30/50\n",
      "iter: 6/20 perturb: 40/50\n",
      "iter: 6/20 perturb: 50/50\n",
      "iter: 7/20 perturb: 10/50\n",
      "iter: 7/20 perturb: 20/50\n",
      "iter: 7/20 perturb: 30/50\n",
      "iter: 7/20 perturb: 40/50\n",
      "iter: 7/20 perturb: 50/50\n",
      "iter: 8/20 perturb: 10/50\n",
      "iter: 8/20 perturb: 20/50\n",
      "iter: 8/20 perturb: 30/50\n",
      "iter: 8/20 perturb: 40/50\n",
      "iter: 8/20 perturb: 50/50\n",
      "iter: 9/20 perturb: 10/50\n",
      "iter: 9/20 perturb: 20/50\n",
      "iter: 9/20 perturb: 30/50\n",
      "iter: 9/20 perturb: 40/50\n",
      "iter: 9/20 perturb: 50/50\n",
      "iter: 10/20 perturb: 10/50\n",
      "iter: 10/20 perturb: 20/50\n",
      "iter: 10/20 perturb: 30/50\n",
      "iter: 10/20 perturb: 40/50\n",
      "iter: 10/20 perturb: 50/50\n",
      "iter: 11/20 perturb: 10/50\n",
      "iter: 11/20 perturb: 20/50\n",
      "iter: 11/20 perturb: 30/50\n",
      "iter: 11/20 perturb: 40/50\n",
      "iter: 11/20 perturb: 50/50\n",
      "iter: 12/20 perturb: 10/50\n",
      "iter: 12/20 perturb: 20/50\n",
      "iter: 12/20 perturb: 30/50\n",
      "iter: 12/20 perturb: 40/50\n",
      "iter: 12/20 perturb: 50/50\n",
      "iter: 13/20 perturb: 10/50\n",
      "iter: 13/20 perturb: 20/50\n",
      "iter: 13/20 perturb: 30/50\n",
      "iter: 13/20 perturb: 40/50\n",
      "iter: 13/20 perturb: 50/50\n",
      "iter: 14/20 perturb: 10/50\n",
      "iter: 14/20 perturb: 20/50\n",
      "iter: 14/20 perturb: 30/50\n",
      "iter: 14/20 perturb: 40/50\n",
      "iter: 14/20 perturb: 50/50\n",
      "iter: 15/20 perturb: 10/50\n",
      "iter: 15/20 perturb: 20/50\n",
      "iter: 15/20 perturb: 30/50\n",
      "iter: 15/20 perturb: 40/50\n",
      "iter: 15/20 perturb: 50/50\n",
      "iter: 16/20 perturb: 10/50\n",
      "iter: 16/20 perturb: 20/50\n",
      "iter: 16/20 perturb: 30/50\n",
      "iter: 16/20 perturb: 40/50\n",
      "iter: 16/20 perturb: 50/50\n",
      "iter: 17/20 perturb: 10/50\n",
      "iter: 17/20 perturb: 20/50\n",
      "iter: 17/20 perturb: 30/50\n",
      "iter: 17/20 perturb: 40/50\n",
      "iter: 17/20 perturb: 50/50\n",
      "iter: 18/20 perturb: 10/50\n",
      "iter: 18/20 perturb: 20/50\n",
      "iter: 18/20 perturb: 30/50\n",
      "iter: 18/20 perturb: 40/50\n",
      "iter: 18/20 perturb: 50/50\n",
      "iter: 19/20 perturb: 10/50\n",
      "iter: 19/20 perturb: 20/50\n",
      "iter: 19/20 perturb: 30/50\n",
      "iter: 19/20 perturb: 40/50\n",
      "iter: 19/20 perturb: 50/50\n",
      "iter: 20/20 perturb: 10/50\n",
      "iter: 20/20 perturb: 20/50\n",
      "iter: 20/20 perturb: 30/50\n",
      "iter: 20/20 perturb: 40/50\n",
      "iter: 20/20 perturb: 50/50\n"
     ]
    }
   ],
   "source": [
    "# find out loss differences (L_forget)\n",
    "criterion = MSELossDiv2()\n",
    "forget_loss_differences = torch.zeros(num_of_perturbations).to(device)\n",
    "sample_count = 0\n",
    "mixed_linear.eval()\n",
    "with torch.no_grad():\n",
    "    for iter, (data, label) in enumerate(forget_loader):\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        label = label * 5\n",
    "        preds = mixed_linear(core_model_state_dict, data)\n",
    "        actual_loss = criterion(preds, label)\n",
    "        sample_count += data.shape[0]\n",
    "        for perturb_idx, perturbed_weight in enumerate(perturbed_weights):\n",
    "            mixed_linear.to('cpu')\n",
    "            state_dict = mixed_linear.state_dict()\n",
    "            for key, perturbed in zip(state_dict.keys(), perturbed_weight):\n",
    "                state_dict[key] = perturbed\n",
    "            mixed_linear.load_state_dict(state_dict)\n",
    "            mixed_linear.to(device)\n",
    "            perturbed_preds = mixed_linear(core_model_state_dict, data)\n",
    "            perturbed_loss = criterion(perturbed_preds, label)\n",
    "            forget_loss_differences[perturb_idx] += (perturbed_loss - actual_loss) * 2 * data.shape[0]\n",
    "            if (perturb_idx + 1) % 10 == 0 or (perturb_idx + 1) == len(forget_loader):\n",
    "                print('iter: {}/{} perturb: {}/{}'.format(iter + 1, len(forget_loader), perturb_idx + 1, len(perturbed_weights)))\n",
    "    forget_loss_differences = forget_loss_differences / sample_count\n",
    "    forget_loss_differences = forget_loss_differences.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T01:18:54.598888Z",
     "start_time": "2024-05-16T01:18:54.594661Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exact_hessian = (forget_hessian * len(forget_dataset) + remain_hessian * len(remaining_dataset)) / (len(remaining_dataset) + len(forget_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-16T01:34:43.694859Z"
    },
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.5.1                                    \n",
      "===============================================================================\n",
      "(CVXPY) May 15 11:30:06 PM: Your problem has 262144 variables, 524289 constraints, and 0 parameters.\n",
      "(CVXPY) May 15 11:30:06 PM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) May 15 11:30:06 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) May 15 11:30:06 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "(CVXPY) May 15 11:30:06 PM: Your problem is compiled with the CPP canonicalization backend.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) May 15 11:30:06 PM: Compiling problem (target solver=SCS).\n",
      "(CVXPY) May 15 11:30:06 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> SCS\n",
      "(CVXPY) May 15 11:30:06 PM: Applying reduction Dcp2Cone\n",
      "(CVXPY) May 15 11:30:06 PM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) May 15 11:30:06 PM: Applying reduction ConeMatrixStuffing\n",
      "(CVXPY) May 15 11:32:08 PM: Applying reduction SCS\n",
      "(CVXPY) May 15 11:32:08 PM: Finished problem compilation (took 1.221e+02 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) May 15 11:32:08 PM: Invoking solver SCS  to obtain a solution.\n",
      "------------------------------------------------------------------\n",
      "\t       SCS v3.2.4 - Splitting Conic Solver\n",
      "\t(c) Brendan O'Donoghue, Stanford University, 2012\n",
      "------------------------------------------------------------------\n",
      "problem:  variables n: 262144, constraints m: 262657\n",
      "cones: \t  l: linear vars: 1\n",
      "\t  s: psd vars: 262656, ssize: 2\n",
      "settings: eps_abs: 1.0e-05, eps_rel: 1.0e-05, eps_infeas: 1.0e-07\n",
      "\t  alpha: 1.50, scale: 1.00e-01, adaptive_scale: 1\n",
      "\t  max_iters: 100000, normalize: 1, rho_x: 1.00e-06\n",
      "\t  acceleration_lookback: 10, acceleration_interval: 10\n",
      "lin-sys:  sparse-direct-amd-qdldl\n",
      "\t  nnz(A): 524800, nnz(P): 0\n",
      "------------------------------------------------------------------\n",
      " iter | pri res | dua res |   gap   |   obj   |  scale  | time (s)\n",
      "------------------------------------------------------------------\n",
      "     0| 1.23e+00  3.60e-01  1.20e+04  6.01e+03  1.00e-01  5.56e-01 \n",
      "   250| 3.64e-02  3.63e-07  1.54e-03  3.07e-01  1.81e-06  2.37e+01 \n",
      "   500| 3.52e-02  3.01e-08  1.36e-03  3.09e-01  1.00e-06  4.53e+01 \n",
      "   750| 3.21e-02  1.31e-08  1.22e-03  3.09e-01  1.00e-06  6.70e+01 \n",
      "  1000| 2.82e-02  5.83e-09  1.10e-03  3.10e-01  1.00e-06  8.81e+01 \n",
      "  1250| 2.44e-02  3.84e-09  1.00e-03  3.10e-01  1.00e-06  1.09e+02 \n",
      "  1500| 2.25e-02  2.47e-09  9.18e-04  3.11e-01  1.00e-06  1.30e+02 \n",
      "  1750| 2.09e-02  1.74e-09  8.48e-04  3.11e-01  1.00e-06  1.52e+02 \n",
      "  2000| 1.97e-02  1.25e-09  7.89e-04  3.11e-01  1.00e-06  1.72e+02 \n",
      "  2250| 1.86e-02  9.69e-10  7.32e-04  3.11e-01  1.00e-06  1.94e+02 \n",
      "  2500| 4.05e+00  2.96e-06  4.53e-04  3.13e-01  1.00e-06  2.15e+02 \n",
      "  2750| 1.67e-02  6.61e-10  6.37e-04  3.12e-01  1.00e-06  2.36e+02 \n",
      "  3000| 1.61e-02  5.55e-10  5.99e-04  3.12e-01  1.00e-06  2.56e+02 \n",
      "  3250| 1.54e-02  4.91e-10  5.65e-04  3.12e-01  1.00e-06  2.77e+02 \n",
      "  3500| 1.47e-02  4.29e-10  5.36e-04  3.12e-01  1.00e-06  2.99e+02 \n",
      "  3750| 1.36e-02  7.46e-10  5.13e-04  3.12e-01  1.00e-06  3.20e+02 \n",
      "  4000| 1.30e-02  3.41e-10  4.84e-04  3.13e-01  1.00e-06  3.41e+02 \n",
      "  4250| 1.25e-02  2.81e-10  4.61e-04  3.13e-01  1.00e-06  3.62e+02 \n",
      "  4500| 1.19e-02  2.72e-10  4.40e-04  3.13e-01  1.00e-06  3.83e+02 \n",
      "  4750| 1.13e-02  2.17e-10  4.19e-04  3.13e-01  1.00e-06  4.04e+02 \n",
      "  5000| 1.09e-02  2.35e-10  4.02e-04  3.13e-01  1.00e-06  4.26e+02 \n",
      "  5250| 1.61e+01  1.15e-05  2.21e-04  3.14e-01  1.00e-06  4.47e+02 \n",
      "  5500| 1.04e-02  2.09e-10  3.71e-04  3.13e-01  1.00e-06  4.68e+02 \n",
      "  5750| 9.79e-03  4.81e-10  3.53e-04  3.13e-01  1.00e-06  4.89e+02 \n",
      "  6000| 9.51e-03  1.99e-10  3.42e-04  3.13e-01  1.00e-06  5.10e+02 \n",
      "  6250| 9.25e-03  1.80e-10  3.29e-04  3.13e-01  1.00e-06  5.31e+02 \n",
      "  6500| 9.00e-03  4.38e-10  3.16e-04  3.13e-01  1.00e-06  5.53e+02 \n",
      "  6750| 8.66e-03  1.69e-10  3.07e-04  3.13e-01  1.00e-06  5.74e+02 \n",
      "  7000| 8.42e-03  4.22e-10  2.94e-04  3.13e-01  1.00e-06  5.95e+02 \n",
      "  7250| 8.27e-03  1.45e-10  2.86e-04  3.13e-01  1.00e-06  6.16e+02 \n",
      "  7500| 8.03e-03  1.37e-10  2.76e-04  3.14e-01  1.00e-06  6.37e+02 \n",
      "  7750| 7.97e-03  1.41e-10  2.70e-04  3.14e-01  1.00e-06  6.59e+02 \n",
      "  8000| 2.63e-02  1.38e-08  2.61e-04  3.14e-01  1.00e-06  6.80e+02 \n",
      "  8250| 7.58e-03  1.64e-10  2.53e-04  3.14e-01  1.00e-06  7.02e+02 \n",
      "  8500| 7.23e-03  1.23e-10  2.44e-04  3.14e-01  1.00e-06  7.23e+02 \n",
      "  8750| 7.02e-03  1.29e-10  2.37e-04  3.14e-01  1.00e-06  7.45e+02 \n",
      "  9000| 6.88e-03  1.18e-10  2.28e-04  3.14e-01  1.00e-06  7.66e+02 \n",
      "  9250| 6.65e-03  1.31e-10  2.22e-04  3.14e-01  1.00e-06  7.88e+02 \n",
      "  9500| 6.00e-03  6.60e-10  4.72e-04  3.14e-01  3.16e-06  8.09e+02 \n",
      "  9750| 5.60e-03  7.80e-10  4.29e-04  3.14e-01  3.16e-06  8.31e+02 \n",
      " 10000| 5.28e-03  5.63e-10  4.00e-04  3.14e-01  3.16e-06  8.53e+02 \n",
      " 10250| 4.84e-03  5.18e-10  3.72e-04  3.14e-01  3.16e-06  8.74e+02 \n",
      " 10500| 4.40e-03  5.12e-10  3.40e-04  3.14e-01  3.16e-06  8.96e+02 \n",
      " 10750| 3.73e-03  4.68e-10  3.09e-04  3.14e-01  3.16e-06  9.18e+02 \n",
      " 11000| 1.43e+01  3.20e-05  6.77e-06  3.15e-01  3.16e-06  9.40e+02 \n",
      " 11250| 2.96e-03  4.38e-10  2.57e-04  3.14e-01  3.16e-06  9.62e+02 \n",
      " 11500| 2.86e-03  3.95e-10  2.35e-04  3.14e-01  3.16e-06  9.84e+02 \n",
      " 11750| 2.69e-03  3.07e-10  2.18e-04  3.14e-01  3.16e-06  1.01e+03 \n",
      " 12000| 2.56e-03  2.43e-10  2.05e-04  3.14e-01  3.16e-06  1.03e+03 \n",
      " 12250| 2.32e-03  3.83e-10  1.81e-04  3.14e-01  3.16e-06  1.05e+03 \n",
      " 12500| 2.27e-03  2.55e-10  1.71e-04  3.14e-01  3.16e-06  1.07e+03 \n",
      " 12750| 1.93e-03  7.27e-10  1.45e-04  3.14e-01  3.16e-06  1.09e+03 \n",
      " 13000| 1.75e-03  1.60e-10  1.26e-04  3.14e-01  3.16e-06  1.12e+03 \n",
      " 13250| 1.59e-03  1.59e-10  1.12e-04  3.14e-01  3.16e-06  1.14e+03 \n",
      " 13500| 1.44e-03  2.15e-10  9.63e-05  3.14e-01  3.16e-06  1.16e+03 \n",
      " 13750| 1.15e-03  3.04e-10  7.80e-05  3.14e-01  3.16e-06  1.18e+03 \n",
      " 14000| 1.14e-03  4.28e-09  2.40e-07  3.15e-01  3.16e-06  1.21e+03 \n",
      "------------------------------------------------------------------\n",
      "status:  solved\n",
      "timings: total: 1.21e+03s = setup: 4.21e-01s + solve: 1.21e+03s\n",
      "\t lin-sys: 9.32e+01s, cones: 1.08e+03s, accel: 9.54e+00s\n",
      "------------------------------------------------------------------\n",
      "objective = 0.314540\n",
      "------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) May 15 11:52:14 PM: Problem status: optimal\n",
      "(CVXPY) May 15 11:52:14 PM: Optimal value: 3.085e-01\n",
      "(CVXPY) May 15 11:52:14 PM: Compilation took 1.221e+02 seconds\n",
      "(CVXPY) May 15 11:52:14 PM: Solver (including time spent in interface) took 1.206e+03 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.30845208076164055"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set optimization problem\n",
    "H = cp.Variable(exact_hessian.shape)\n",
    "# exact_H = cp.kron(H, np.eye(perturbations[0][0].shape[0]))\n",
    "# losses = cp.matmul(stacked_linearized_perturbations.T, cp.matmul(exact_H, stacked_linearized_perturbations))\n",
    "loss = None\n",
    "for perturbation in perturbations:\n",
    "    perturbation = perturbation[0].numpy()\n",
    "    if loss is None:\n",
    "        loss = cp.trace(cp.matmul(perturbation, cp.matmul(H, perturbation.T)))\n",
    "    else:\n",
    "        loss = loss + cp.trace(cp.matmul(perturbation, cp.matmul(H, perturbation.T)))\n",
    "loss = (loss / (2 * len(perturbations))) - np.mean(forget_loss_differences.numpy())\n",
    "# loss = (cp.trace(losses) / (2 * losses.shape[0])) - np.mean(forget_loss_differences.numpy())\n",
    "objective = cp.Minimize(loss)\n",
    "constraints = [H >> 0, cp.trace(H) >= 0, H >> forget_hessian.numpy()]\n",
    "problem = cp.Problem(objective, constraints)\n",
    "problem.solve(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2021, 0.7860, 0.7426,  ..., 0.7782, 0.8685, 0.7422],\n",
       "        [0.7860, 1.2532, 0.8470,  ..., 0.8283, 0.9643, 0.7790],\n",
       "        [0.7426, 0.8470, 1.1877,  ..., 0.7974, 0.8329, 0.7588],\n",
       "        ...,\n",
       "        [0.7782, 0.8283, 0.7974,  ..., 1.3197, 0.9226, 0.8003],\n",
       "        [0.8685, 0.9643, 0.8329,  ..., 0.9226, 1.6868, 0.9451],\n",
       "        [0.7422, 0.7790, 0.7588,  ..., 0.8003, 0.9451, 1.3192]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = torch.tensor(H.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'predicted_hessian': H  \n",
    "}, os.path.join(exp_path, '05152024_011132_train_user_data_resnet18_cifar10_last1_predicted_hessian.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predicted_hessian': tensor([[1.1896, 0.7855, 0.7525,  ..., 0.7829, 0.8623, 0.7398],\n",
       "         [0.7855, 1.2301, 0.8390,  ..., 0.8050, 0.9582, 0.7773],\n",
       "         [0.7525, 0.8390, 1.1924,  ..., 0.7987, 0.8402, 0.7594],\n",
       "         ...,\n",
       "         [0.7829, 0.8050, 0.7987,  ..., 1.3358, 0.9210, 0.8063],\n",
       "         [0.8623, 0.9582, 0.8402,  ..., 0.9210, 1.7189, 0.9601],\n",
       "         [0.7398, 0.7773, 0.7594,  ..., 0.8063, 0.9601, 1.3156]],\n",
       "        dtype=torch.float64)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "exp_path = 'checkpoint/tmp'\n",
    "torch.load(os.path.join(exp_path, '05152024_011132_train_user_data_resnet18_cifar10_last1_predicted_hessian.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-stable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
