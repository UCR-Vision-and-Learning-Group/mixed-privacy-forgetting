{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# date: 04.29.24"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "nRp8Bxusbjlh",
    "outputId": "87e64861-2ac4-431c-e662-62df6d2404f7"
   },
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "# Define Jacobian-vector product function\n",
    "def set_attr(obj, names, value):\n",
    "    \"\"\"\n",
    "    Set attribute value by nested names.\n",
    "    \"\"\"\n",
    "    for name in names[:-1]:\n",
    "        obj = getattr(obj, name)\n",
    "    setattr(obj, names[-1], value)\n",
    "\n",
    "def del_attr(obj, names):\n",
    "    \"\"\"\n",
    "    Delete attribute by nested names.\n",
    "    \"\"\"\n",
    "    for name in names[:-1]:\n",
    "        obj = getattr(obj, name)\n",
    "    delattr(obj, names[-1])\n",
    "\n",
    "def jacobian_vector_product(model, inputs, vector):\n",
    "    params = {name: p for name, p in model.named_parameters()}\n",
    "    tangents = {name: vec_pt for name, vec_pt in zip(params.keys(), vector)}\n",
    "\n",
    "    jvp = None\n",
    "    with torch.autograd.forward_ad.dual_level():\n",
    "        for name, p in params.items():\n",
    "            tangent = tangents[name]\n",
    "            del_attr(model, name.split(\".\"))\n",
    "            set_attr(model, name.split(\".\"), torch.autograd.forward_ad.make_dual(p, tangent))\n",
    "\n",
    "        out = model(inputs)\n",
    "        jvp = out.clone().detach()\n",
    "\n",
    "    return jvp\n",
    "\n",
    "\n",
    "# Load pre-trained ResNet18 model\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "# Initialize vector\n",
    "vector = [torch.randn_like(p, requires_grad=True) for p in model.parameters()]\n",
    "\n",
    "# Define optimizer to only optimize the parameters in vector\n",
    "optimizer = optim.SGD(vector, lr=0.001)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# CIFAR10 data loading and preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to match ResNet input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        jvp = jacobian_vector_product(model, inputs, vector)\n",
    "        combined_output = outputs + jvp\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(combined_output, targets)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print loss\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item()}')\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lcLbukRMe66W",
    "outputId": "15765486-64f4-42b2-ba95-ffa140ede92a"
   },
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.transforms import transforms\n",
    "import numpy as np\n",
    "\n",
    "# Define Jacobian-vector product function\n",
    "def set_attr(obj, names, value):\n",
    "    \"\"\"\n",
    "    Set attribute value by nested names.\n",
    "    \"\"\"\n",
    "    for name in names[:-1]:\n",
    "        obj = getattr(obj, name)\n",
    "    setattr(obj, names[-1], value)\n",
    "\n",
    "def del_attr(obj, names):\n",
    "    \"\"\"\n",
    "    Delete attribute by nested names.\n",
    "    \"\"\"\n",
    "    for name in names[:-1]:\n",
    "        obj = getattr(obj, name)\n",
    "    delattr(obj, names[-1])\n",
    "\n",
    "def jacobian_vector_product(model, inputs, vector):\n",
    "    params = {name: p for name, p in model.named_parameters()}\n",
    "    tangents = {name: vec_pt for name, vec_pt in zip(params.keys(), vector)}\n",
    "\n",
    "    jvp = None\n",
    "    with torch.autograd.forward_ad.dual_level():\n",
    "        for name, p in params.items():\n",
    "            tangent = tangents[name]\n",
    "            del_attr(model, name.split(\".\"))\n",
    "            set_attr(model, name.split(\".\"), torch.autograd.forward_ad.make_dual(p, tangent))\n",
    "\n",
    "        out = model(inputs)\n",
    "        jvp = out.clone().detach()\n",
    "\n",
    "    return jvp\n",
    "\n",
    "\n",
    "# Load pre-trained ResNet18 model\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "# Initialize vector\n",
    "vector = [torch.randn_like(p, requires_grad=True) for p in model.parameters()]\n",
    "\n",
    "# Define optimizer to only optimize the parameters in vector\n",
    "optimizer = optim.SGD(vector, lr=0.01)\n",
    "\n",
    "criterion = nn.MSELoss()  # MSE Loss\n",
    "\n",
    "# CIFAR10 data loading and preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to match ResNet input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# Use only 20% of the data\n",
    "subset_indices = np.random.choice(len(train_dataset), size=int(0.2 * len(train_dataset)), replace=False)\n",
    "train_subset = Subset(train_dataset, subset_indices)\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        jvp = jacobian_vector_product(model, inputs, vector)\n",
    "        combined_output = outputs + jvp\n",
    "\n",
    "        # Resize targets to match the batch size\n",
    "        targets_resized = targets.unsqueeze(1).expand_as(combined_output)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(combined_output, targets_resized.float())\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print loss\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item()}')\n"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
