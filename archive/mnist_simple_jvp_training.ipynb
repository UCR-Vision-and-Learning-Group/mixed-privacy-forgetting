{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.func import functional_call\n",
    "import torch.autograd.forward_ad as fwAD\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "from model import SimpleNet\n",
    "from dataset import get_core_train_loader, split_dataset_core_train\n",
    "\n",
    "model = SimpleNet(784, 10)\n",
    "checkpoint = torch.load('./checkpoints/042924-train-core-dataset-mnist/last_checkpoint.pth')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "params = {name: p.detach().clone().to(device) for name, p in model.named_parameters()}\n",
    "del model\n",
    "\n",
    "_, train_dataset = split_dataset_core_train('mnist', 'simple', 0.2)\n",
    "_, train_loader = get_core_train_loader(_, train_dataset, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lin_1.weight': tensor([[ 0.0208,  0.0336,  0.0317,  ...,  0.0054,  0.0312,  0.0195],\n",
      "        [ 0.0208, -0.0243, -0.0056,  ..., -0.0243,  0.0037,  0.0152],\n",
      "        [ 0.0162,  0.0131, -0.0214,  ...,  0.0194,  0.0005,  0.0351],\n",
      "        ...,\n",
      "        [-0.0551, -0.0420, -0.0266,  ...,  0.0027, -0.0332, -0.0093],\n",
      "        [ 0.0195,  0.0358,  0.0273,  ...,  0.0100,  0.0219,  0.0078],\n",
      "        [ 0.0364,  0.0124,  0.0196,  ...,  0.0343,  0.0170,  0.0218]],\n",
      "       device='cuda:0'), 'lin_1.bias': tensor([ 0.0095,  0.0004,  0.0197,  0.0114, -0.0445,  0.0104, -0.0115, -0.0331,\n",
      "         0.0105, -0.0243,  0.0063, -0.0338,  0.0037, -0.0364, -0.0052, -0.0204,\n",
      "        -0.0054, -0.0315, -0.0095,  0.0188,  0.0281,  0.0110,  0.0150,  0.0233,\n",
      "         0.0278, -0.0041,  0.0072,  0.0102,  0.0416, -0.0135, -0.0125,  0.0089,\n",
      "         0.0245, -0.0384,  0.0027, -0.0257,  0.0003, -0.0337,  0.0234, -0.0157,\n",
      "        -0.0351,  0.0114, -0.0169, -0.0192, -0.0372, -0.0257, -0.0181,  0.0144,\n",
      "        -0.0060, -0.0163, -0.0060, -0.0346, -0.0059,  0.0126,  0.0112, -0.0074,\n",
      "        -0.0352, -0.0029,  0.0345,  0.0056,  0.0250,  0.0387, -0.0122, -0.0210,\n",
      "         0.0040,  0.0111,  0.0310, -0.0005, -0.0093, -0.0242,  0.0271,  0.0070,\n",
      "         0.0023,  0.0115,  0.0180, -0.0339, -0.0263,  0.0221, -0.0098, -0.0372,\n",
      "        -0.0006,  0.0319,  0.0278, -0.0345, -0.0325, -0.0288, -0.0163,  0.0063,\n",
      "        -0.0131,  0.0008,  0.0098, -0.0088,  0.0173, -0.0172, -0.0267, -0.0416,\n",
      "        -0.0283, -0.0287,  0.0092,  0.0255,  0.0019, -0.0148,  0.0187, -0.0297,\n",
      "         0.0019, -0.0473,  0.0079, -0.0371,  0.0155,  0.0147, -0.0354, -0.0390,\n",
      "        -0.0126, -0.0228,  0.0402, -0.0303, -0.0256, -0.0222,  0.0106,  0.0049,\n",
      "         0.0220,  0.0327,  0.0121,  0.0288, -0.0368,  0.0607, -0.0445,  0.0054],\n",
      "       device='cuda:0'), 'lin_2.weight': tensor([[-1.6304e-01,  8.9202e-02, -3.8661e-02,  ...,  2.6317e-01,\n",
      "         -5.4033e-02, -6.7928e-02],\n",
      "        [ 1.9714e-01,  2.3372e-01, -6.5984e-02,  ...,  3.4844e-01,\n",
      "          1.7239e-01, -7.6504e-03],\n",
      "        [ 6.9412e-02,  1.1178e-01,  1.6402e-01,  ..., -4.5647e-02,\n",
      "          1.6000e-01,  1.0212e-04],\n",
      "        ...,\n",
      "        [-1.7932e-01,  1.1167e-02, -4.0152e-03,  ...,  1.9406e-01,\n",
      "          2.7239e-01, -2.3260e-02],\n",
      "        [ 1.9544e-01, -1.6786e-01, -4.4863e-01,  ..., -1.6950e-01,\n",
      "         -4.9682e-01,  8.3781e-02],\n",
      "        [-4.2580e-01, -4.8554e-02,  7.1551e-03,  ..., -4.0022e-01,\n",
      "         -5.8033e-01, -1.2186e-01]], device='cuda:0'), 'lin_2.bias': tensor([-0.0246, -0.0657, -0.0348,  0.0592, -0.0158,  0.0398,  0.0210, -0.0695,\n",
      "         0.0402,  0.0804], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixedLinear(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.tangent_model = SimpleNet(784, 10) \n",
    "        self.tangents = {name: p for name, p in self.tangent_model.named_parameters()}\n",
    "    \n",
    "    def forward(self, params, x):\n",
    "        dual_params = {}\n",
    "        with fwAD.dual_level():\n",
    "            for name, p in params.items():\n",
    "                dual_params[name] = fwAD.make_dual(p, self.tangents[name])\n",
    "            out = functional_call(self.tangent_model, dual_params, x)\n",
    "            jvp = fwAD.unpack_dual(out).tangent\n",
    "        return out + jvp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_linear = MixedLinear()\n",
    "mixed_linear = mixed_linear.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lin_1.weight': Parameter containing:\n",
       " tensor([[ 0.0200, -0.0089, -0.0070,  ..., -0.0355, -0.0322, -0.0152],\n",
       "         [ 0.0178,  0.0353,  0.0136,  ..., -0.0044,  0.0349, -0.0337],\n",
       "         [ 0.0165,  0.0110, -0.0238,  ..., -0.0047,  0.0092,  0.0350],\n",
       "         ...,\n",
       "         [-0.0174, -0.0197, -0.0018,  ...,  0.0297,  0.0218,  0.0176],\n",
       "         [-0.0319,  0.0075, -0.0006,  ..., -0.0277,  0.0324,  0.0008],\n",
       "         [ 0.0107,  0.0331, -0.0029,  ...,  0.0101,  0.0118,  0.0353]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " 'lin_1.bias': Parameter containing:\n",
       " tensor([-3.2776e-02, -1.6389e-03, -3.2103e-02, -4.2866e-03, -2.3340e-02,\n",
       "          8.1726e-05,  4.9326e-03,  1.6578e-02,  5.0908e-03,  3.1007e-03,\n",
       "         -2.9043e-02, -1.6292e-02, -2.1973e-02, -3.4411e-03, -1.7099e-02,\n",
       "         -2.2489e-02,  1.0228e-02, -2.8306e-03, -2.7606e-02, -4.1055e-03,\n",
       "         -1.3854e-02,  2.7847e-02, -6.8181e-03,  3.5263e-02,  2.8912e-02,\n",
       "         -1.8661e-02,  1.7160e-02,  8.4342e-03, -1.7303e-02, -2.8621e-02,\n",
       "         -8.3778e-03,  3.2604e-02,  7.9732e-03, -8.0810e-03, -9.7450e-03,\n",
       "         -3.5277e-02,  3.4980e-02, -4.9353e-03,  3.3339e-03,  2.4665e-02,\n",
       "         -1.7719e-02,  2.6556e-03,  2.3203e-03, -1.7021e-03,  1.8188e-02,\n",
       "         -1.9174e-02,  2.0476e-02, -7.7417e-04, -5.8531e-03, -4.5674e-03,\n",
       "          1.4425e-02,  1.4945e-02, -8.7241e-03, -3.2400e-02,  2.1036e-02,\n",
       "          1.5237e-02, -2.7934e-02, -3.2164e-03, -2.8730e-03,  2.5050e-02,\n",
       "         -3.1670e-02,  8.9098e-03,  2.2376e-02, -2.6961e-02, -1.6596e-02,\n",
       "         -3.2606e-02,  2.6078e-02,  2.2415e-02,  7.2275e-03, -1.6848e-02,\n",
       "         -1.7580e-02, -1.4370e-02, -2.6135e-02, -1.1373e-03, -2.9333e-02,\n",
       "          3.4518e-02,  2.6107e-02,  1.5166e-02, -3.2300e-02,  3.1580e-02,\n",
       "         -2.3975e-03,  1.3267e-02, -3.8022e-03, -8.7224e-03,  2.3789e-02,\n",
       "         -6.6839e-03, -1.4917e-02, -2.5320e-02,  2.4592e-02,  8.8565e-03,\n",
       "         -2.5516e-02, -1.0001e-02, -9.1671e-03,  8.9590e-03,  3.1879e-02,\n",
       "          3.5201e-02, -1.6169e-02, -3.2932e-03,  7.4775e-03, -1.6779e-02,\n",
       "         -3.0104e-02,  1.4156e-02, -2.1517e-02,  7.8332e-03, -2.7845e-02,\n",
       "         -7.7424e-03, -2.3920e-02, -1.3072e-03, -1.9206e-02,  6.2022e-04,\n",
       "          9.0626e-03, -1.4252e-02, -9.9213e-03,  2.6126e-02, -2.8626e-02,\n",
       "         -2.7696e-02,  1.1195e-03, -2.7358e-02, -3.2246e-02, -1.9805e-02,\n",
       "         -2.9301e-02, -2.8741e-02, -1.4462e-02,  4.4149e-03,  2.2241e-02,\n",
       "          3.4697e-02, -1.3130e-02,  2.1427e-02], device='cuda:0',\n",
       "        requires_grad=True),\n",
       " 'lin_2.weight': Parameter containing:\n",
       " tensor([[ 0.0460, -0.0825, -0.0584,  ..., -0.0820,  0.0790,  0.0592],\n",
       "         [-0.0877, -0.0604,  0.0257,  ..., -0.0045,  0.0253, -0.0135],\n",
       "         [ 0.0866, -0.0858, -0.0874,  ...,  0.0700, -0.0827, -0.0852],\n",
       "         ...,\n",
       "         [-0.0696,  0.0065, -0.0568,  ...,  0.0248, -0.0464,  0.0314],\n",
       "         [-0.0041, -0.0296,  0.0385,  ...,  0.0060, -0.0771, -0.0795],\n",
       "         [ 0.0110, -0.0758,  0.0374,  ..., -0.0158, -0.0416, -0.0360]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " 'lin_2.bias': Parameter containing:\n",
       " tensor([-0.0180,  0.0290,  0.0225,  0.0089,  0.0316, -0.0037, -0.0851, -0.0190,\n",
       "          0.0138,  0.0681], device='cuda:0', requires_grad=True)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_linear.tangents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0200, -0.0089, -0.0070,  ..., -0.0355, -0.0322, -0.0152],\n",
       "         [ 0.0178,  0.0353,  0.0136,  ..., -0.0044,  0.0349, -0.0337],\n",
       "         [ 0.0165,  0.0110, -0.0238,  ..., -0.0047,  0.0092,  0.0350],\n",
       "         ...,\n",
       "         [-0.0174, -0.0197, -0.0018,  ...,  0.0297,  0.0218,  0.0176],\n",
       "         [-0.0319,  0.0075, -0.0006,  ..., -0.0277,  0.0324,  0.0008],\n",
       "         [ 0.0107,  0.0331, -0.0029,  ...,  0.0101,  0.0118,  0.0353]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-3.2776e-02, -1.6389e-03, -3.2103e-02, -4.2866e-03, -2.3340e-02,\n",
       "          8.1726e-05,  4.9326e-03,  1.6578e-02,  5.0908e-03,  3.1007e-03,\n",
       "         -2.9043e-02, -1.6292e-02, -2.1973e-02, -3.4411e-03, -1.7099e-02,\n",
       "         -2.2489e-02,  1.0228e-02, -2.8306e-03, -2.7606e-02, -4.1055e-03,\n",
       "         -1.3854e-02,  2.7847e-02, -6.8181e-03,  3.5263e-02,  2.8912e-02,\n",
       "         -1.8661e-02,  1.7160e-02,  8.4342e-03, -1.7303e-02, -2.8621e-02,\n",
       "         -8.3778e-03,  3.2604e-02,  7.9732e-03, -8.0810e-03, -9.7450e-03,\n",
       "         -3.5277e-02,  3.4980e-02, -4.9353e-03,  3.3339e-03,  2.4665e-02,\n",
       "         -1.7719e-02,  2.6556e-03,  2.3203e-03, -1.7021e-03,  1.8188e-02,\n",
       "         -1.9174e-02,  2.0476e-02, -7.7417e-04, -5.8531e-03, -4.5674e-03,\n",
       "          1.4425e-02,  1.4945e-02, -8.7241e-03, -3.2400e-02,  2.1036e-02,\n",
       "          1.5237e-02, -2.7934e-02, -3.2164e-03, -2.8730e-03,  2.5050e-02,\n",
       "         -3.1670e-02,  8.9098e-03,  2.2376e-02, -2.6961e-02, -1.6596e-02,\n",
       "         -3.2606e-02,  2.6078e-02,  2.2415e-02,  7.2275e-03, -1.6848e-02,\n",
       "         -1.7580e-02, -1.4370e-02, -2.6135e-02, -1.1373e-03, -2.9333e-02,\n",
       "          3.4518e-02,  2.6107e-02,  1.5166e-02, -3.2300e-02,  3.1580e-02,\n",
       "         -2.3975e-03,  1.3267e-02, -3.8022e-03, -8.7224e-03,  2.3789e-02,\n",
       "         -6.6839e-03, -1.4917e-02, -2.5320e-02,  2.4592e-02,  8.8565e-03,\n",
       "         -2.5516e-02, -1.0001e-02, -9.1671e-03,  8.9590e-03,  3.1879e-02,\n",
       "          3.5201e-02, -1.6169e-02, -3.2932e-03,  7.4775e-03, -1.6779e-02,\n",
       "         -3.0104e-02,  1.4156e-02, -2.1517e-02,  7.8332e-03, -2.7845e-02,\n",
       "         -7.7424e-03, -2.3920e-02, -1.3072e-03, -1.9206e-02,  6.2022e-04,\n",
       "          9.0626e-03, -1.4252e-02, -9.9213e-03,  2.6126e-02, -2.8626e-02,\n",
       "         -2.7696e-02,  1.1195e-03, -2.7358e-02, -3.2246e-02, -1.9805e-02,\n",
       "         -2.9301e-02, -2.8741e-02, -1.4462e-02,  4.4149e-03,  2.2241e-02,\n",
       "          3.4697e-02, -1.3130e-02,  2.1427e-02], device='cuda:0',\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0460, -0.0825, -0.0584,  ..., -0.0820,  0.0790,  0.0592],\n",
       "         [-0.0877, -0.0604,  0.0257,  ..., -0.0045,  0.0253, -0.0135],\n",
       "         [ 0.0866, -0.0858, -0.0874,  ...,  0.0700, -0.0827, -0.0852],\n",
       "         ...,\n",
       "         [-0.0696,  0.0065, -0.0568,  ...,  0.0248, -0.0464,  0.0314],\n",
       "         [-0.0041, -0.0296,  0.0385,  ...,  0.0060, -0.0771, -0.0795],\n",
       "         [ 0.0110, -0.0758,  0.0374,  ..., -0.0158, -0.0416, -0.0360]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0180,  0.0290,  0.0225,  0.0089,  0.0316, -0.0037, -0.0851, -0.0190,\n",
       "          0.0138,  0.0681], device='cuda:0', requires_grad=True)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[param for param in mixed_linear.tangent_model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, iter_idx: 1, loss: 235.1256866455078\n",
      "epoch: 1, iter_idx: 50, loss: 20.913421630859375\n",
      "epoch: 1, iter_idx: 94, loss: 13.852892875671387\n",
      "epoch: 1, accuracy: 0.3179166666666667\n",
      "epoch: 2, iter_idx: 1, loss: 12.282530784606934\n",
      "epoch: 2, iter_idx: 50, loss: 9.477126121520996\n",
      "epoch: 2, iter_idx: 94, loss: 7.5135321617126465\n",
      "epoch: 2, accuracy: 0.30316666666666664\n",
      "epoch: 3, iter_idx: 1, loss: 7.1286821365356445\n",
      "epoch: 3, iter_idx: 50, loss: 5.605279445648193\n",
      "epoch: 3, iter_idx: 94, loss: 4.649112224578857\n",
      "epoch: 3, accuracy: 0.30725\n",
      "epoch: 4, iter_idx: 1, loss: 4.4858832359313965\n",
      "epoch: 4, iter_idx: 50, loss: 3.8514435291290283\n",
      "epoch: 4, iter_idx: 94, loss: 3.0707461833953857\n",
      "epoch: 4, accuracy: 0.32016666666666665\n",
      "epoch: 5, iter_idx: 1, loss: 2.8337345123291016\n",
      "epoch: 5, iter_idx: 50, loss: 2.5082554817199707\n",
      "epoch: 5, iter_idx: 94, loss: 2.6235270500183105\n",
      "epoch: 5, accuracy: 0.31333333333333335\n",
      "epoch: 6, iter_idx: 1, loss: 2.4107778072357178\n",
      "epoch: 6, iter_idx: 50, loss: 1.9695236682891846\n",
      "epoch: 6, iter_idx: 94, loss: 1.758915662765503\n",
      "epoch: 6, accuracy: 0.34108333333333335\n",
      "epoch: 7, iter_idx: 1, loss: 1.772290587425232\n",
      "epoch: 7, iter_idx: 50, loss: 1.506234049797058\n",
      "epoch: 7, iter_idx: 94, loss: 1.5502347946166992\n",
      "epoch: 7, accuracy: 0.35583333333333333\n",
      "epoch: 8, iter_idx: 1, loss: 1.3102848529815674\n",
      "epoch: 8, iter_idx: 50, loss: 1.1840474605560303\n",
      "epoch: 8, iter_idx: 94, loss: 1.1553997993469238\n",
      "epoch: 8, accuracy: 0.37833333333333335\n",
      "epoch: 9, iter_idx: 1, loss: 0.9660850763320923\n",
      "epoch: 9, iter_idx: 50, loss: 0.9280359148979187\n",
      "epoch: 9, iter_idx: 94, loss: 0.8424381613731384\n",
      "epoch: 9, accuracy: 0.3898333333333333\n",
      "epoch: 10, iter_idx: 1, loss: 0.7954302430152893\n",
      "epoch: 10, iter_idx: 50, loss: 0.7099522352218628\n",
      "epoch: 10, iter_idx: 94, loss: 0.6300199627876282\n",
      "epoch: 10, accuracy: 0.43275\n",
      "epoch: 11, iter_idx: 1, loss: 0.5826740860939026\n",
      "epoch: 11, iter_idx: 50, loss: 0.59489506483078\n",
      "epoch: 11, iter_idx: 94, loss: 0.5537145733833313\n",
      "epoch: 11, accuracy: 0.4925\n",
      "epoch: 12, iter_idx: 1, loss: 0.503692626953125\n",
      "epoch: 12, iter_idx: 50, loss: 0.5106378197669983\n",
      "epoch: 12, iter_idx: 94, loss: 0.46629366278648376\n",
      "epoch: 12, accuracy: 0.49683333333333335\n",
      "epoch: 13, iter_idx: 1, loss: 0.43058234453201294\n",
      "epoch: 13, iter_idx: 50, loss: 0.3962080478668213\n",
      "epoch: 13, iter_idx: 94, loss: 0.36119145154953003\n",
      "epoch: 13, accuracy: 0.5508333333333333\n",
      "epoch: 14, iter_idx: 1, loss: 0.35049501061439514\n",
      "epoch: 14, iter_idx: 50, loss: 0.3325843811035156\n",
      "epoch: 14, iter_idx: 94, loss: 0.33628103137016296\n",
      "epoch: 14, accuracy: 0.54925\n",
      "epoch: 15, iter_idx: 1, loss: 0.3268451690673828\n",
      "epoch: 15, iter_idx: 50, loss: 0.3054450452327728\n",
      "epoch: 15, iter_idx: 94, loss: 0.31731054186820984\n",
      "epoch: 15, accuracy: 0.6006666666666667\n",
      "epoch: 16, iter_idx: 1, loss: 0.2615022659301758\n",
      "epoch: 16, iter_idx: 50, loss: 0.25194695591926575\n",
      "epoch: 16, iter_idx: 94, loss: 0.2514762580394745\n",
      "epoch: 16, accuracy: 0.62925\n",
      "epoch: 17, iter_idx: 1, loss: 0.2405669242143631\n",
      "epoch: 17, iter_idx: 50, loss: 0.23600387573242188\n",
      "epoch: 17, iter_idx: 94, loss: 0.23336228728294373\n",
      "epoch: 17, accuracy: 0.6635\n",
      "epoch: 18, iter_idx: 1, loss: 0.20231786370277405\n",
      "epoch: 18, iter_idx: 50, loss: 0.2102380245923996\n",
      "epoch: 18, iter_idx: 94, loss: 0.1960490345954895\n",
      "epoch: 18, accuracy: 0.68425\n",
      "epoch: 19, iter_idx: 1, loss: 0.17478926479816437\n",
      "epoch: 19, iter_idx: 50, loss: 0.18603985011577606\n",
      "epoch: 19, iter_idx: 94, loss: 0.17229552567005157\n",
      "epoch: 19, accuracy: 0.7075\n",
      "epoch: 20, iter_idx: 1, loss: 0.16246595978736877\n",
      "epoch: 20, iter_idx: 50, loss: 0.15645678341388702\n",
      "epoch: 20, iter_idx: 94, loss: 0.16787934303283691\n",
      "epoch: 20, accuracy: 0.75425\n",
      "epoch: 21, iter_idx: 1, loss: 0.14427900314331055\n",
      "epoch: 21, iter_idx: 50, loss: 0.14241819083690643\n",
      "epoch: 21, iter_idx: 94, loss: 0.16228128969669342\n",
      "epoch: 21, accuracy: 0.7551666666666667\n",
      "epoch: 22, iter_idx: 1, loss: 0.14166076481342316\n",
      "epoch: 22, iter_idx: 50, loss: 0.12915769219398499\n",
      "epoch: 22, iter_idx: 94, loss: 0.13663463294506073\n",
      "epoch: 22, accuracy: 0.79125\n",
      "epoch: 23, iter_idx: 1, loss: 0.12038774788379669\n",
      "epoch: 23, iter_idx: 50, loss: 0.13610783219337463\n",
      "epoch: 23, iter_idx: 94, loss: 0.11732332408428192\n",
      "epoch: 23, accuracy: 0.82\n",
      "epoch: 24, iter_idx: 1, loss: 0.10567188262939453\n",
      "epoch: 24, iter_idx: 50, loss: 0.1068480983376503\n",
      "epoch: 24, iter_idx: 94, loss: 0.12285059690475464\n",
      "epoch: 24, accuracy: 0.8245\n",
      "epoch: 25, iter_idx: 1, loss: 0.09333609789609909\n",
      "epoch: 25, iter_idx: 50, loss: 0.09429077059030533\n",
      "epoch: 25, iter_idx: 94, loss: 0.09671390056610107\n",
      "epoch: 25, accuracy: 0.8561666666666666\n",
      "epoch: 26, iter_idx: 1, loss: 0.09890200197696686\n",
      "epoch: 26, iter_idx: 50, loss: 0.09172939509153366\n",
      "epoch: 26, iter_idx: 94, loss: 0.09748252481222153\n",
      "epoch: 26, accuracy: 0.8763333333333333\n",
      "epoch: 27, iter_idx: 1, loss: 0.08081652969121933\n",
      "epoch: 27, iter_idx: 50, loss: 0.07972452789545059\n",
      "epoch: 27, iter_idx: 94, loss: 0.08356109261512756\n",
      "epoch: 27, accuracy: 0.8961666666666667\n",
      "epoch: 28, iter_idx: 1, loss: 0.07917126268148422\n",
      "epoch: 28, iter_idx: 50, loss: 0.07452342659235\n",
      "epoch: 28, iter_idx: 94, loss: 0.0839335173368454\n",
      "epoch: 28, accuracy: 0.9091666666666667\n",
      "epoch: 29, iter_idx: 1, loss: 0.07420443743467331\n",
      "epoch: 29, iter_idx: 50, loss: 0.07838914543390274\n",
      "epoch: 29, iter_idx: 94, loss: 0.06188284978270531\n",
      "epoch: 29, accuracy: 0.9200833333333334\n",
      "epoch: 30, iter_idx: 1, loss: 0.0579124353826046\n",
      "epoch: 30, iter_idx: 50, loss: 0.06259282678365707\n",
      "epoch: 30, iter_idx: 94, loss: 0.07012847065925598\n",
      "epoch: 30, accuracy: 0.9281666666666667\n",
      "epoch: 31, iter_idx: 1, loss: 0.061310019344091415\n",
      "epoch: 31, iter_idx: 50, loss: 0.05636303499341011\n",
      "epoch: 31, iter_idx: 94, loss: 0.0547347292304039\n",
      "epoch: 31, accuracy: 0.9378333333333333\n",
      "epoch: 32, iter_idx: 1, loss: 0.05752788856625557\n",
      "epoch: 32, iter_idx: 50, loss: 0.05635080486536026\n",
      "epoch: 32, iter_idx: 94, loss: 0.056992024183273315\n",
      "epoch: 32, accuracy: 0.9461666666666667\n",
      "epoch: 33, iter_idx: 1, loss: 0.04997336491942406\n",
      "epoch: 33, iter_idx: 50, loss: 0.04962737113237381\n",
      "epoch: 33, iter_idx: 94, loss: 0.051574353128671646\n",
      "epoch: 33, accuracy: 0.9519166666666666\n",
      "epoch: 34, iter_idx: 1, loss: 0.05301600694656372\n",
      "epoch: 34, iter_idx: 50, loss: 0.049898624420166016\n",
      "epoch: 34, iter_idx: 94, loss: 0.05193059891462326\n",
      "epoch: 34, accuracy: 0.9574166666666667\n",
      "epoch: 35, iter_idx: 1, loss: 0.045199062675237656\n",
      "epoch: 35, iter_idx: 50, loss: 0.046023495495319366\n",
      "epoch: 35, iter_idx: 94, loss: 0.04810792952775955\n",
      "epoch: 35, accuracy: 0.96425\n",
      "epoch: 36, iter_idx: 1, loss: 0.039557501673698425\n",
      "epoch: 36, iter_idx: 50, loss: 0.04375668987631798\n",
      "epoch: 36, iter_idx: 94, loss: 0.04186544194817543\n",
      "epoch: 36, accuracy: 0.9653333333333334\n",
      "epoch: 37, iter_idx: 1, loss: 0.03950604423880577\n",
      "epoch: 37, iter_idx: 50, loss: 0.04244042560458183\n",
      "epoch: 37, iter_idx: 94, loss: 0.03884787857532501\n",
      "epoch: 37, accuracy: 0.9715833333333334\n",
      "epoch: 38, iter_idx: 1, loss: 0.041897762566804886\n",
      "epoch: 38, iter_idx: 50, loss: 0.036813877522945404\n",
      "epoch: 38, iter_idx: 94, loss: 0.03761507198214531\n",
      "epoch: 38, accuracy: 0.9731666666666666\n",
      "epoch: 39, iter_idx: 1, loss: 0.03246968612074852\n",
      "epoch: 39, iter_idx: 50, loss: 0.0359632782638073\n",
      "epoch: 39, iter_idx: 94, loss: 0.03857020288705826\n",
      "epoch: 39, accuracy: 0.9753333333333334\n",
      "epoch: 40, iter_idx: 1, loss: 0.03769348934292793\n",
      "epoch: 40, iter_idx: 50, loss: 0.03528984263539314\n",
      "epoch: 40, iter_idx: 94, loss: 0.03778029605746269\n",
      "epoch: 40, accuracy: 0.9785833333333334\n",
      "epoch: 41, iter_idx: 1, loss: 0.03211432322859764\n",
      "epoch: 41, iter_idx: 50, loss: 0.03584575280547142\n",
      "epoch: 41, iter_idx: 94, loss: 0.0364200659096241\n",
      "epoch: 41, accuracy: 0.9790833333333333\n",
      "epoch: 42, iter_idx: 1, loss: 0.03322013467550278\n",
      "epoch: 42, iter_idx: 50, loss: 0.034400563687086105\n",
      "epoch: 42, iter_idx: 94, loss: 0.031166912987828255\n",
      "epoch: 42, accuracy: 0.9845\n",
      "epoch: 43, iter_idx: 1, loss: 0.02904444746673107\n",
      "epoch: 43, iter_idx: 50, loss: 0.02964593470096588\n",
      "epoch: 43, iter_idx: 94, loss: 0.03303305059671402\n",
      "epoch: 43, accuracy: 0.9835\n",
      "epoch: 44, iter_idx: 1, loss: 0.028311312198638916\n",
      "epoch: 44, iter_idx: 50, loss: 0.027499699965119362\n",
      "epoch: 44, iter_idx: 94, loss: 0.030522610992193222\n",
      "epoch: 44, accuracy: 0.9865833333333334\n",
      "epoch: 45, iter_idx: 1, loss: 0.027467746287584305\n",
      "epoch: 45, iter_idx: 50, loss: 0.02895178273320198\n",
      "epoch: 45, iter_idx: 94, loss: 0.03392937406897545\n",
      "epoch: 45, accuracy: 0.9874166666666667\n",
      "epoch: 46, iter_idx: 1, loss: 0.028845274820923805\n",
      "epoch: 46, iter_idx: 50, loss: 0.02762085571885109\n",
      "epoch: 46, iter_idx: 94, loss: 0.029792366549372673\n",
      "epoch: 46, accuracy: 0.9874166666666667\n",
      "epoch: 47, iter_idx: 1, loss: 0.029735714197158813\n",
      "epoch: 47, iter_idx: 50, loss: 0.02891254797577858\n",
      "epoch: 47, iter_idx: 94, loss: 0.025343574583530426\n",
      "epoch: 47, accuracy: 0.9875\n",
      "epoch: 48, iter_idx: 1, loss: 0.02980637364089489\n",
      "epoch: 48, iter_idx: 50, loss: 0.025185663253068924\n",
      "epoch: 48, iter_idx: 94, loss: 0.025679800659418106\n",
      "epoch: 48, accuracy: 0.9905\n",
      "epoch: 49, iter_idx: 1, loss: 0.023631811141967773\n",
      "epoch: 49, iter_idx: 50, loss: 0.025001326575875282\n",
      "epoch: 49, iter_idx: 94, loss: 0.028594208881258965\n",
      "epoch: 49, accuracy: 0.9915\n",
      "epoch: 50, iter_idx: 1, loss: 0.02421276830136776\n",
      "epoch: 50, iter_idx: 50, loss: 0.0257151760160923\n",
      "epoch: 50, iter_idx: 94, loss: 0.027180977165699005\n",
      "epoch: 50, accuracy: 0.9896666666666667\n",
      "epoch: 51, iter_idx: 1, loss: 0.0241414662450552\n",
      "epoch: 51, iter_idx: 50, loss: 0.022020822390913963\n",
      "epoch: 51, iter_idx: 94, loss: 0.0241604745388031\n",
      "epoch: 51, accuracy: 0.9914166666666666\n",
      "epoch: 52, iter_idx: 1, loss: 0.02262158878147602\n",
      "epoch: 52, iter_idx: 50, loss: 0.025635218247771263\n",
      "epoch: 52, iter_idx: 94, loss: 0.026383792981505394\n",
      "epoch: 52, accuracy: 0.9911666666666666\n",
      "epoch: 53, iter_idx: 1, loss: 0.02276328206062317\n",
      "epoch: 53, iter_idx: 50, loss: 0.026682322844862938\n",
      "epoch: 53, iter_idx: 94, loss: 0.029145527631044388\n",
      "epoch: 53, accuracy: 0.9904166666666666\n",
      "epoch: 54, iter_idx: 1, loss: 0.027401894330978394\n",
      "epoch: 54, iter_idx: 50, loss: 0.04072469100356102\n",
      "epoch: 54, iter_idx: 94, loss: 0.029035065323114395\n",
      "epoch: 54, accuracy: 0.9930833333333333\n",
      "epoch: 55, iter_idx: 1, loss: 0.02221100963652134\n",
      "epoch: 55, iter_idx: 50, loss: 0.022955097258090973\n",
      "epoch: 55, iter_idx: 94, loss: 0.020640743896365166\n",
      "epoch: 55, accuracy: 0.9928333333333333\n",
      "epoch: 56, iter_idx: 1, loss: 0.020050926133990288\n",
      "epoch: 56, iter_idx: 50, loss: 0.021207474172115326\n",
      "epoch: 56, iter_idx: 94, loss: 0.029721325263381004\n",
      "epoch: 56, accuracy: 0.9930833333333333\n",
      "epoch: 57, iter_idx: 1, loss: 0.023687202483415604\n",
      "epoch: 57, iter_idx: 50, loss: 0.025357091799378395\n",
      "epoch: 57, iter_idx: 94, loss: 0.027470732107758522\n",
      "epoch: 57, accuracy: 0.9935\n",
      "epoch: 58, iter_idx: 1, loss: 0.019055072218179703\n",
      "epoch: 58, iter_idx: 50, loss: 0.025305842980742455\n",
      "epoch: 58, iter_idx: 94, loss: 0.025378428399562836\n",
      "epoch: 58, accuracy: 0.9943333333333333\n",
      "epoch: 59, iter_idx: 1, loss: 0.02277231775224209\n",
      "epoch: 59, iter_idx: 50, loss: 0.02498449571430683\n",
      "epoch: 59, iter_idx: 94, loss: 0.02660759538412094\n",
      "epoch: 59, accuracy: 0.9926666666666667\n",
      "epoch: 60, iter_idx: 1, loss: 0.023336848244071007\n",
      "epoch: 60, iter_idx: 50, loss: 0.023485267534852028\n",
      "epoch: 60, iter_idx: 94, loss: 0.025019338354468346\n",
      "epoch: 60, accuracy: 0.9918333333333333\n",
      "epoch: 61, iter_idx: 1, loss: 0.025626003742218018\n",
      "epoch: 61, iter_idx: 50, loss: 0.024542829021811485\n",
      "epoch: 61, iter_idx: 94, loss: 0.021910956129431725\n",
      "epoch: 61, accuracy: 0.9940833333333333\n",
      "epoch: 62, iter_idx: 1, loss: 0.021808331832289696\n",
      "epoch: 62, iter_idx: 50, loss: 0.021142741665244102\n",
      "epoch: 62, iter_idx: 94, loss: 0.026653891429305077\n",
      "epoch: 62, accuracy: 0.98725\n",
      "epoch: 63, iter_idx: 1, loss: 0.02578457072377205\n",
      "epoch: 63, iter_idx: 50, loss: 0.025130867958068848\n",
      "epoch: 63, iter_idx: 94, loss: 0.023884756490588188\n",
      "epoch: 63, accuracy: 0.995\n",
      "epoch: 64, iter_idx: 1, loss: 0.021303553134202957\n",
      "epoch: 64, iter_idx: 50, loss: 0.030354727059602737\n",
      "epoch: 64, iter_idx: 94, loss: 0.031046723946928978\n",
      "epoch: 64, accuracy: 0.9950833333333333\n",
      "epoch: 65, iter_idx: 1, loss: 0.02456955797970295\n",
      "epoch: 65, iter_idx: 50, loss: 0.027925077825784683\n",
      "epoch: 65, iter_idx: 94, loss: 0.028343504294753075\n",
      "epoch: 65, accuracy: 0.9940833333333333\n",
      "epoch: 66, iter_idx: 1, loss: 0.021578559651970863\n",
      "epoch: 66, iter_idx: 50, loss: 0.023906854912638664\n",
      "epoch: 66, iter_idx: 94, loss: 0.02671632170677185\n",
      "epoch: 66, accuracy: 0.9955\n",
      "epoch: 67, iter_idx: 1, loss: 0.02450457029044628\n",
      "epoch: 67, iter_idx: 50, loss: 0.02484910748898983\n",
      "epoch: 67, iter_idx: 94, loss: 0.02538357675075531\n",
      "epoch: 67, accuracy: 0.9919166666666667\n",
      "epoch: 68, iter_idx: 1, loss: 0.0277405958622694\n",
      "epoch: 68, iter_idx: 50, loss: 0.020266776904463768\n",
      "epoch: 68, iter_idx: 94, loss: 0.0272067878395319\n",
      "epoch: 68, accuracy: 0.9964166666666666\n",
      "epoch: 69, iter_idx: 1, loss: 0.021396029740571976\n",
      "epoch: 69, iter_idx: 50, loss: 0.017660049721598625\n",
      "epoch: 69, iter_idx: 94, loss: 0.025941111147403717\n",
      "epoch: 69, accuracy: 0.9950833333333333\n",
      "epoch: 70, iter_idx: 1, loss: 0.02517525665462017\n",
      "epoch: 70, iter_idx: 50, loss: 0.025040937587618828\n",
      "epoch: 70, iter_idx: 94, loss: 0.029206732288002968\n",
      "epoch: 70, accuracy: 0.9944166666666666\n",
      "epoch: 71, iter_idx: 1, loss: 0.023816797882318497\n",
      "epoch: 71, iter_idx: 50, loss: 0.020755883306264877\n",
      "epoch: 71, iter_idx: 94, loss: 0.024077605456113815\n",
      "epoch: 71, accuracy: 0.9961666666666666\n",
      "epoch: 72, iter_idx: 1, loss: 0.021948372945189476\n",
      "epoch: 72, iter_idx: 50, loss: 0.020477330312132835\n",
      "epoch: 72, iter_idx: 94, loss: 0.02018863521516323\n",
      "epoch: 72, accuracy: 0.9948333333333333\n",
      "epoch: 73, iter_idx: 1, loss: 0.024162186309695244\n",
      "epoch: 73, iter_idx: 50, loss: 0.025374725461006165\n",
      "epoch: 73, iter_idx: 94, loss: 0.026546964421868324\n",
      "epoch: 73, accuracy: 0.9958333333333333\n",
      "epoch: 74, iter_idx: 1, loss: 0.02051139809191227\n",
      "epoch: 74, iter_idx: 50, loss: 0.022847581654787064\n",
      "epoch: 74, iter_idx: 94, loss: 0.021781837567687035\n",
      "epoch: 74, accuracy: 0.9960833333333333\n",
      "epoch: 75, iter_idx: 1, loss: 0.023566076532006264\n",
      "epoch: 75, iter_idx: 50, loss: 0.021761396899819374\n",
      "epoch: 75, iter_idx: 94, loss: 0.02084781788289547\n",
      "epoch: 75, accuracy: 0.9960833333333333\n",
      "epoch: 76, iter_idx: 1, loss: 0.02225535921752453\n",
      "epoch: 76, iter_idx: 50, loss: 0.02506372332572937\n",
      "epoch: 76, iter_idx: 94, loss: 0.02559412643313408\n",
      "epoch: 76, accuracy: 0.9960833333333333\n",
      "epoch: 77, iter_idx: 1, loss: 0.026097601279616356\n",
      "epoch: 77, iter_idx: 50, loss: 0.023932723328471184\n",
      "epoch: 77, iter_idx: 94, loss: 0.021651865914463997\n",
      "epoch: 77, accuracy: 0.9976666666666667\n",
      "epoch: 78, iter_idx: 1, loss: 0.020519942045211792\n",
      "epoch: 78, iter_idx: 50, loss: 0.025162024423480034\n",
      "epoch: 78, iter_idx: 94, loss: 0.022115012630820274\n",
      "epoch: 78, accuracy: 0.9934166666666666\n",
      "epoch: 79, iter_idx: 1, loss: 0.026258409023284912\n",
      "epoch: 79, iter_idx: 50, loss: 0.02066924422979355\n",
      "epoch: 79, iter_idx: 94, loss: 0.022148625925183296\n",
      "epoch: 79, accuracy: 0.9959166666666667\n",
      "epoch: 80, iter_idx: 1, loss: 0.023238180205225945\n",
      "epoch: 80, iter_idx: 50, loss: 0.023449501022696495\n",
      "epoch: 80, iter_idx: 94, loss: 0.027756020426750183\n",
      "epoch: 80, accuracy: 0.9933333333333333\n",
      "epoch: 81, iter_idx: 1, loss: 0.02761334739625454\n",
      "epoch: 81, iter_idx: 50, loss: 0.022047419100999832\n",
      "epoch: 81, iter_idx: 94, loss: 0.02900524064898491\n",
      "epoch: 81, accuracy: 0.9970833333333333\n",
      "epoch: 82, iter_idx: 1, loss: 0.02399398572742939\n",
      "epoch: 82, iter_idx: 50, loss: 0.02561853639781475\n",
      "epoch: 82, iter_idx: 94, loss: 0.026749491691589355\n",
      "epoch: 82, accuracy: 0.9920833333333333\n",
      "epoch: 83, iter_idx: 1, loss: 0.033321138471364975\n",
      "epoch: 83, iter_idx: 50, loss: 0.02501528337597847\n",
      "epoch: 83, iter_idx: 94, loss: 0.027233336120843887\n",
      "epoch: 83, accuracy: 0.9971666666666666\n",
      "epoch: 84, iter_idx: 1, loss: 0.02303772047162056\n",
      "epoch: 84, iter_idx: 50, loss: 0.024483434855937958\n",
      "epoch: 84, iter_idx: 94, loss: 0.026881052181124687\n",
      "epoch: 84, accuracy: 0.9951666666666666\n",
      "epoch: 85, iter_idx: 1, loss: 0.02614620327949524\n",
      "epoch: 85, iter_idx: 50, loss: 0.03147933632135391\n",
      "epoch: 85, iter_idx: 94, loss: 0.024274449795484543\n",
      "epoch: 85, accuracy: 0.99625\n",
      "epoch: 86, iter_idx: 1, loss: 0.027033692225813866\n",
      "epoch: 86, iter_idx: 50, loss: 0.021763870492577553\n",
      "epoch: 86, iter_idx: 94, loss: 0.022036219015717506\n",
      "epoch: 86, accuracy: 0.9968333333333333\n",
      "epoch: 87, iter_idx: 1, loss: 0.02085348404943943\n",
      "epoch: 87, iter_idx: 50, loss: 0.017068911343812943\n",
      "epoch: 87, iter_idx: 94, loss: 0.021129559725522995\n",
      "epoch: 87, accuracy: 0.9973333333333333\n",
      "epoch: 88, iter_idx: 1, loss: 0.019322704523801804\n",
      "epoch: 88, iter_idx: 50, loss: 0.02478780411183834\n",
      "epoch: 88, iter_idx: 94, loss: 0.024548634886741638\n",
      "epoch: 88, accuracy: 0.99675\n",
      "epoch: 89, iter_idx: 1, loss: 0.02011718973517418\n",
      "epoch: 89, iter_idx: 50, loss: 0.025540977716445923\n",
      "epoch: 89, iter_idx: 94, loss: 0.020982487127184868\n",
      "epoch: 89, accuracy: 0.9985\n",
      "epoch: 90, iter_idx: 1, loss: 0.018300337716937065\n",
      "epoch: 90, iter_idx: 50, loss: 0.019640779122710228\n",
      "epoch: 90, iter_idx: 94, loss: 0.026289943605661392\n",
      "epoch: 90, accuracy: 0.996\n",
      "epoch: 91, iter_idx: 1, loss: 0.025023385882377625\n",
      "epoch: 91, iter_idx: 50, loss: 0.018611324951052666\n",
      "epoch: 91, iter_idx: 94, loss: 0.01984485052525997\n",
      "epoch: 91, accuracy: 0.9965\n",
      "epoch: 92, iter_idx: 1, loss: 0.019447414204478264\n",
      "epoch: 92, iter_idx: 50, loss: 0.023392168805003166\n",
      "epoch: 92, iter_idx: 94, loss: 0.02129117213189602\n",
      "epoch: 92, accuracy: 0.9981666666666666\n",
      "epoch: 93, iter_idx: 1, loss: 0.0158152524381876\n",
      "epoch: 93, iter_idx: 50, loss: 0.038032617419958115\n",
      "epoch: 93, iter_idx: 94, loss: 0.02674199640750885\n",
      "epoch: 93, accuracy: 0.9959166666666667\n",
      "epoch: 94, iter_idx: 1, loss: 0.027385467663407326\n",
      "epoch: 94, iter_idx: 50, loss: 0.026922557502985\n",
      "epoch: 94, iter_idx: 94, loss: 0.024019936099648476\n",
      "epoch: 94, accuracy: 0.99675\n",
      "epoch: 95, iter_idx: 1, loss: 0.02114146016538143\n",
      "epoch: 95, iter_idx: 50, loss: 0.018129972741007805\n",
      "epoch: 95, iter_idx: 94, loss: 0.017415445297956467\n",
      "epoch: 95, accuracy: 0.9986666666666667\n",
      "epoch: 96, iter_idx: 1, loss: 0.015851113945245743\n",
      "epoch: 96, iter_idx: 50, loss: 0.019610807299613953\n",
      "epoch: 96, iter_idx: 94, loss: 0.021832874044775963\n",
      "epoch: 96, accuracy: 0.9973333333333333\n",
      "epoch: 97, iter_idx: 1, loss: 0.020966125652194023\n",
      "epoch: 97, iter_idx: 50, loss: 0.020500529557466507\n",
      "epoch: 97, iter_idx: 94, loss: 0.023450881242752075\n",
      "epoch: 97, accuracy: 0.99675\n",
      "epoch: 98, iter_idx: 1, loss: 0.019074365496635437\n",
      "epoch: 98, iter_idx: 50, loss: 0.02021942101418972\n",
      "epoch: 98, iter_idx: 94, loss: 0.02002532035112381\n",
      "epoch: 98, accuracy: 0.9966666666666667\n",
      "epoch: 99, iter_idx: 1, loss: 0.02478758804500103\n",
      "epoch: 99, iter_idx: 50, loss: 0.021622033789753914\n",
      "epoch: 99, iter_idx: 94, loss: 0.025492146611213684\n",
      "epoch: 99, accuracy: 0.9964166666666666\n",
      "epoch: 100, iter_idx: 1, loss: 0.021934350952506065\n",
      "epoch: 100, iter_idx: 50, loss: 0.02570915035903454\n",
      "epoch: 100, iter_idx: 94, loss: 0.02051106095314026\n",
      "epoch: 100, accuracy: 0.9970833333333333\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(mixed_linear.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(100):\n",
    "    mixed_linear.train()\n",
    "    for iter_idx, (data, label) in enumerate(train_loader):\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        data = data.reshape((-1, 784))\n",
    "        optimizer.zero_grad()\n",
    "        preds = mixed_linear(params, data)\n",
    "        loss = criterion(preds, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if iter_idx == 0 or (iter_idx + 1) % 50 == 0 or (iter_idx + 1) == len(train_loader): \n",
    "            print('epoch: {}, iter_idx: {}, loss: {}'.format(epoch + 1, iter_idx + 1, loss.item()))\n",
    "    \n",
    "    mixed_linear.eval()\n",
    "    with torch.no_grad():\n",
    "        true_count = 0\n",
    "        sample_count = 0\n",
    "        for data, label in train_loader:\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            data = data.reshape((-1, 784))\n",
    "            preds = mixed_linear(params, data)\n",
    "            predicted_labels = torch.argmax(preds, dim=1)\n",
    "            ground_truth = torch.argmax(label, dim=1)\n",
    "            true_count += torch.count_nonzero(predicted_labels == ground_truth).item()\n",
    "            sample_count += data.shape[0]\n",
    "        print('epoch: {}, accuracy: {}'.format(epoch + 1, (true_count / sample_count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lin_1.weight': tensor([[ 0.0208,  0.0336,  0.0317,  ...,  0.0054,  0.0312,  0.0195],\n",
       "         [ 0.0208, -0.0243, -0.0056,  ..., -0.0243,  0.0037,  0.0152],\n",
       "         [ 0.0162,  0.0131, -0.0214,  ...,  0.0194,  0.0005,  0.0351],\n",
       "         ...,\n",
       "         [-0.0551, -0.0420, -0.0266,  ...,  0.0027, -0.0332, -0.0093],\n",
       "         [ 0.0195,  0.0358,  0.0273,  ...,  0.0100,  0.0219,  0.0078],\n",
       "         [ 0.0364,  0.0124,  0.0196,  ...,  0.0343,  0.0170,  0.0218]],\n",
       "        device='cuda:0'),\n",
       " 'lin_1.bias': tensor([ 0.0095,  0.0004,  0.0197,  0.0114, -0.0445,  0.0104, -0.0115, -0.0331,\n",
       "          0.0105, -0.0243,  0.0063, -0.0338,  0.0037, -0.0364, -0.0052, -0.0204,\n",
       "         -0.0054, -0.0315, -0.0095,  0.0188,  0.0281,  0.0110,  0.0150,  0.0233,\n",
       "          0.0278, -0.0041,  0.0072,  0.0102,  0.0416, -0.0135, -0.0125,  0.0089,\n",
       "          0.0245, -0.0384,  0.0027, -0.0257,  0.0003, -0.0337,  0.0234, -0.0157,\n",
       "         -0.0351,  0.0114, -0.0169, -0.0192, -0.0372, -0.0257, -0.0181,  0.0144,\n",
       "         -0.0060, -0.0163, -0.0060, -0.0346, -0.0059,  0.0126,  0.0112, -0.0074,\n",
       "         -0.0352, -0.0029,  0.0345,  0.0056,  0.0250,  0.0387, -0.0122, -0.0210,\n",
       "          0.0040,  0.0111,  0.0310, -0.0005, -0.0093, -0.0242,  0.0271,  0.0070,\n",
       "          0.0023,  0.0115,  0.0180, -0.0339, -0.0263,  0.0221, -0.0098, -0.0372,\n",
       "         -0.0006,  0.0319,  0.0278, -0.0345, -0.0325, -0.0288, -0.0163,  0.0063,\n",
       "         -0.0131,  0.0008,  0.0098, -0.0088,  0.0173, -0.0172, -0.0267, -0.0416,\n",
       "         -0.0283, -0.0287,  0.0092,  0.0255,  0.0019, -0.0148,  0.0187, -0.0297,\n",
       "          0.0019, -0.0473,  0.0079, -0.0371,  0.0155,  0.0147, -0.0354, -0.0390,\n",
       "         -0.0126, -0.0228,  0.0402, -0.0303, -0.0256, -0.0222,  0.0106,  0.0049,\n",
       "          0.0220,  0.0327,  0.0121,  0.0288, -0.0368,  0.0607, -0.0445,  0.0054],\n",
       "        device='cuda:0'),\n",
       " 'lin_2.weight': tensor([[-1.6304e-01,  8.9202e-02, -3.8661e-02,  ...,  2.6317e-01,\n",
       "          -5.4033e-02, -6.7928e-02],\n",
       "         [ 1.9714e-01,  2.3372e-01, -6.5984e-02,  ...,  3.4844e-01,\n",
       "           1.7239e-01, -7.6504e-03],\n",
       "         [ 6.9412e-02,  1.1178e-01,  1.6402e-01,  ..., -4.5647e-02,\n",
       "           1.6000e-01,  1.0212e-04],\n",
       "         ...,\n",
       "         [-1.7932e-01,  1.1167e-02, -4.0152e-03,  ...,  1.9406e-01,\n",
       "           2.7239e-01, -2.3260e-02],\n",
       "         [ 1.9544e-01, -1.6786e-01, -4.4863e-01,  ..., -1.6950e-01,\n",
       "          -4.9682e-01,  8.3781e-02],\n",
       "         [-4.2580e-01, -4.8554e-02,  7.1551e-03,  ..., -4.0022e-01,\n",
       "          -5.8033e-01, -1.2186e-01]], device='cuda:0'),\n",
       " 'lin_2.bias': tensor([-0.0246, -0.0657, -0.0348,  0.0592, -0.0158,  0.0398,  0.0210, -0.0695,\n",
       "          0.0402,  0.0804], device='cuda:0')}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lin_1.weight': Parameter containing:\n",
       " tensor([[-0.0066, -0.0198,  0.0250,  ..., -0.0190,  0.0086,  0.0204],\n",
       "         [ 0.0261,  0.0283, -0.0039,  ..., -0.0066, -0.0087, -0.0004],\n",
       "         [ 0.0279,  0.0105,  0.0245,  ..., -0.0267, -0.0085, -0.0197],\n",
       "         ...,\n",
       "         [ 0.0298,  0.0151,  0.0262,  ...,  0.0159,  0.0442,  0.0422],\n",
       "         [ 0.0279,  0.0092, -0.0378,  ..., -0.0040,  0.0196, -0.0344],\n",
       "         [-0.0120, -0.0096,  0.0039,  ...,  0.0317,  0.0370,  0.0101]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " 'lin_1.bias': Parameter containing:\n",
       " tensor([-0.0162, -0.0100,  0.0187,  0.0209, -0.0109,  0.0053, -0.0072,  0.0106,\n",
       "         -0.0198, -0.0135, -0.0385,  0.0133, -0.0445, -0.0157, -0.0005,  0.0169,\n",
       "         -0.0282,  0.0248, -0.0379, -0.0052,  0.0254,  0.0207,  0.0285, -0.0328,\n",
       "         -0.0051, -0.0054,  0.0040, -0.0369, -0.0362, -0.0127, -0.0369, -0.0254,\n",
       "         -0.0228, -0.0053,  0.0194,  0.0185,  0.0202, -0.0364,  0.0232,  0.0195,\n",
       "         -0.0066,  0.0183, -0.0361,  0.0032,  0.0269, -0.0149, -0.0308, -0.0384,\n",
       "          0.0167,  0.0297,  0.0017,  0.0236,  0.0284, -0.0121, -0.0348,  0.0250,\n",
       "         -0.0172,  0.0190, -0.0278, -0.0121, -0.0352,  0.0002, -0.0257,  0.0276,\n",
       "         -0.0038, -0.0143,  0.0127, -0.0148,  0.0243,  0.0110,  0.0096, -0.0329,\n",
       "         -0.0353, -0.0303, -0.0028,  0.0080,  0.0164,  0.0301, -0.0270,  0.0380,\n",
       "         -0.0365, -0.0296, -0.0077, -0.0252, -0.0266, -0.0346,  0.0071,  0.0007,\n",
       "          0.0270, -0.0148, -0.0280, -0.0319, -0.0155,  0.0299, -0.0215, -0.0144,\n",
       "         -0.0031, -0.0031,  0.0180, -0.0154, -0.0269, -0.0069,  0.0073,  0.0310,\n",
       "         -0.0034, -0.0156, -0.0121,  0.0045, -0.0320,  0.0162, -0.0234, -0.0299,\n",
       "          0.0069,  0.0270,  0.0284, -0.0145,  0.0191, -0.0110, -0.0269, -0.0015,\n",
       "         -0.0147,  0.0204, -0.0319, -0.0253,  0.0278, -0.0468, -0.0175, -0.0272],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " 'lin_2.weight': Parameter containing:\n",
       " tensor([[ 0.0667, -0.0274,  0.0031,  ..., -0.0792,  0.0907,  0.0271],\n",
       "         [-0.0949, -0.0919,  0.0656,  ..., -0.0669, -0.0920,  0.0341],\n",
       "         [ 0.0296, -0.0359, -0.0640,  ..., -0.0124, -0.0268, -0.0248],\n",
       "         ...,\n",
       "         [ 0.1520,  0.0177, -0.0268,  ..., -0.0779, -0.1098,  0.0428],\n",
       "         [-0.1068,  0.0440,  0.2012,  ...,  0.0594,  0.1582,  0.0005],\n",
       "         [ 0.2104,  0.0939, -0.0173,  ...,  0.1792,  0.1952, -0.0031]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " 'lin_2.bias': Parameter containing:\n",
       " tensor([-0.0219, -0.0318,  0.0401, -0.0629,  0.0009,  0.0427,  0.0571,  0.0110,\n",
       "         -0.0176,  0.0415], device='cuda:0', requires_grad=True)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_linear.tangents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0066, -0.0198,  0.0250,  ..., -0.0190,  0.0086,  0.0204],\n",
       "         [ 0.0261,  0.0283, -0.0039,  ..., -0.0066, -0.0087, -0.0004],\n",
       "         [ 0.0279,  0.0105,  0.0245,  ..., -0.0267, -0.0085, -0.0197],\n",
       "         ...,\n",
       "         [ 0.0298,  0.0151,  0.0262,  ...,  0.0159,  0.0442,  0.0422],\n",
       "         [ 0.0279,  0.0092, -0.0378,  ..., -0.0040,  0.0196, -0.0344],\n",
       "         [-0.0120, -0.0096,  0.0039,  ...,  0.0317,  0.0370,  0.0101]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0162, -0.0100,  0.0187,  0.0209, -0.0109,  0.0053, -0.0072,  0.0106,\n",
       "         -0.0198, -0.0135, -0.0385,  0.0133, -0.0445, -0.0157, -0.0005,  0.0169,\n",
       "         -0.0282,  0.0248, -0.0379, -0.0052,  0.0254,  0.0207,  0.0285, -0.0328,\n",
       "         -0.0051, -0.0054,  0.0040, -0.0369, -0.0362, -0.0127, -0.0369, -0.0254,\n",
       "         -0.0228, -0.0053,  0.0194,  0.0185,  0.0202, -0.0364,  0.0232,  0.0195,\n",
       "         -0.0066,  0.0183, -0.0361,  0.0032,  0.0269, -0.0149, -0.0308, -0.0384,\n",
       "          0.0167,  0.0297,  0.0017,  0.0236,  0.0284, -0.0121, -0.0348,  0.0250,\n",
       "         -0.0172,  0.0190, -0.0278, -0.0121, -0.0352,  0.0002, -0.0257,  0.0276,\n",
       "         -0.0038, -0.0143,  0.0127, -0.0148,  0.0243,  0.0110,  0.0096, -0.0329,\n",
       "         -0.0353, -0.0303, -0.0028,  0.0080,  0.0164,  0.0301, -0.0270,  0.0380,\n",
       "         -0.0365, -0.0296, -0.0077, -0.0252, -0.0266, -0.0346,  0.0071,  0.0007,\n",
       "          0.0270, -0.0148, -0.0280, -0.0319, -0.0155,  0.0299, -0.0215, -0.0144,\n",
       "         -0.0031, -0.0031,  0.0180, -0.0154, -0.0269, -0.0069,  0.0073,  0.0310,\n",
       "         -0.0034, -0.0156, -0.0121,  0.0045, -0.0320,  0.0162, -0.0234, -0.0299,\n",
       "          0.0069,  0.0270,  0.0284, -0.0145,  0.0191, -0.0110, -0.0269, -0.0015,\n",
       "         -0.0147,  0.0204, -0.0319, -0.0253,  0.0278, -0.0468, -0.0175, -0.0272],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0667, -0.0274,  0.0031,  ..., -0.0792,  0.0907,  0.0271],\n",
       "         [-0.0949, -0.0919,  0.0656,  ..., -0.0669, -0.0920,  0.0341],\n",
       "         [ 0.0296, -0.0359, -0.0640,  ..., -0.0124, -0.0268, -0.0248],\n",
       "         ...,\n",
       "         [ 0.1520,  0.0177, -0.0268,  ..., -0.0779, -0.1098,  0.0428],\n",
       "         [-0.1068,  0.0440,  0.2012,  ...,  0.0594,  0.1582,  0.0005],\n",
       "         [ 0.2104,  0.0939, -0.0173,  ...,  0.1792,  0.1952, -0.0031]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0219, -0.0318,  0.0401, -0.0629,  0.0009,  0.0427,  0.0571,  0.0110,\n",
       "         -0.0176,  0.0415], device='cuda:0', requires_grad=True)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[param for param in mixed_linear.tangent_model.parameters()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-stable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
